{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9713b878",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6d3308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-22 14:33:27,881 INFO: Initializing external client\n",
      "2025-12-22 14:33:27,882 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2025-12-22 14:33:29,147 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/2177\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "\n",
    "project = hopsworks.login(host=\"eu-west.cloud.hopsworks.ai\",\n",
    "project=\"EarthTamagotchi\", api_key_value=api_key)\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405b611",
   "metadata": {},
   "source": [
    "## Get references to the Feature Groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16729a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups (same versions as in backfill notebook)\n",
    "co2_fg = fs.get_feature_group(\n",
    "    name='global_co2',\n",
    "    version=1,\n",
    ")\n",
    "temp_fg = fs.get_feature_group(\n",
    "    name='global_temperature',\n",
    "    version=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf67735",
   "metadata": {},
   "source": [
    "## üå´ Retrieve Latest CO‚ÇÇ Data from NOAA GML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e6bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.26s) \n",
      "Latest date in feature store: 2025-11-01\n",
      "No new CO‚ÇÇ data to add\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOAA_CO2_URL = \"https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt\"\n",
    "\n",
    "response = requests.get(NOAA_CO2_URL)\n",
    "response.raise_for_status()\n",
    "\n",
    "# NOAA file has commented header lines starting with '#'\n",
    "lines = response.text.splitlines()\n",
    "data_lines = [ln for ln in lines if ln.strip() and not ln.startswith(\"#\")]\n",
    "\n",
    "raw_text = \"\\n\".join(data_lines)\n",
    "\n",
    "# Columns in Mauna Loa file (see header in the NOAA text):\n",
    "# year, month, decimal_date, average, trend, #days, st.dev, unc. of mon mean\n",
    "co2_df = pd.read_csv(\n",
    "    io.StringIO(raw_text),\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=[\"year\", \"month\", \"decimal_date\", \"average\", \"trend\", \"ndays\", \"stdev\", \"average_unc\"],\n",
    ")\n",
    "\n",
    "# Build a proper datetime (first day of each month)\n",
    "co2_df[\"date\"] = pd.to_datetime(\n",
    "    {\n",
    "        \"year\": co2_df[\"year\"].astype(int),\n",
    "        \"month\": co2_df[\"month\"].astype(int),\n",
    "        \"day\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Replace NOAA missing value marker (-99.99 or -9.99) with NaN\n",
    "for col in [\"average\", \"trend\", \"average_unc\"]:\n",
    "    co2_df[col] = co2_df[col].replace([-99.99, -9.99], pd.NA).astype(\"float32\")\n",
    "\n",
    "co2_df = co2_df.dropna(subset=[\"average\"]).copy()\n",
    "\n",
    "# Keep a tidy subset of columns we care about\n",
    "co2_df = co2_df[[\"date\", \"average\", \"trend\", \"average_unc\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Get the latest date from the feature store to find new data\n",
    "# We'll reuse this historical data later for calculating rolling features\n",
    "historical_co2_df = co2_fg.read()\n",
    "if len(historical_co2_df) > 0:\n",
    "    historical_co2_df['date'] = pd.to_datetime(historical_co2_df['date'])\n",
    "    # Remove timezone info if present (normalize to timezone-naive)\n",
    "    if historical_co2_df['date'].dt.tz is not None:\n",
    "        # Convert to UTC first, then remove timezone\n",
    "        historical_co2_df['date'] = historical_co2_df['date'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "    latest_date = historical_co2_df['date'].max()\n",
    "    print(f\"Latest date in feature store: {latest_date.date()}\")\n",
    "    \n",
    "    # Filter to only new data (after latest date)\n",
    "    co2_df['date'] = pd.to_datetime(co2_df['date'])\n",
    "    # Ensure timezone-naive for comparison\n",
    "    if co2_df['date'].dt.tz is not None:\n",
    "        co2_df['date'] = co2_df['date'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "    co2_new_df = co2_df[co2_df['date'] > latest_date].copy()\n",
    "    \n",
    "    if len(co2_new_df) == 0:\n",
    "        print(\"No new CO‚ÇÇ data to add\")\n",
    "        co2_new_df = pd.DataFrame()  # Empty DataFrame\n",
    "    else:\n",
    "        print(f\"Found {len(co2_new_df)} new month(s) of CO‚ÇÇ data\")\n",
    "else:\n",
    "    print(\"No historical data found in feature store - this should not happen if backfill ran first\")\n",
    "    co2_new_df = pd.DataFrame()  # Empty DataFrame\n",
    "    historical_co2_df = pd.DataFrame()  # Empty DataFrame for consistency\n",
    "\n",
    "co2_new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f254a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new CO‚ÇÇ data to process\n"
     ]
    }
   ],
   "source": [
    "if len(co2_new_df) > 0:\n",
    "    # Get historical data to calculate lags and rolling means\n",
    "    # We need enough history for the maximum lag (12 months)\n",
    "    historical_co2_df = co2_fg.read()\n",
    "    historical_co2_df['date'] = pd.to_datetime(historical_co2_df['date'])\n",
    "    # Remove timezone info if present (normalize to timezone-naive)\n",
    "    if historical_co2_df['date'].dt.tz is not None:\n",
    "        historical_co2_df['date'] = pd.to_datetime(historical_co2_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    historical_co2_df = historical_co2_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Ensure new data dates are also timezone-naive\n",
    "    co2_new_df['date'] = pd.to_datetime(co2_new_df['date'])\n",
    "    if co2_new_df['date'].dt.tz is not None:\n",
    "        co2_new_df['date'] = pd.to_datetime(co2_new_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    \n",
    "    # Combine historical and new data for feature engineering\n",
    "    combined_co2_df = pd.concat([historical_co2_df[['date', 'average', 'trend', 'average_unc']], \n",
    "                                  co2_new_df[['date', 'average', 'trend', 'average_unc']]], \n",
    "                                 ignore_index=True)\n",
    "    combined_co2_df = combined_co2_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Add lag features for the main target series (average CO‚ÇÇ) and for the trend\n",
    "    for k in [1, 2, 3, 6, 12]:\n",
    "        combined_co2_df[f\"average_lag_{k}\"] = combined_co2_df[\"average\"].shift(k)\n",
    "        combined_co2_df[f\"trend_lag_{k}\"] = combined_co2_df[\"trend\"].shift(k)\n",
    "    \n",
    "    # Add rolling means over the average and trend series\n",
    "    # IMPORTANT: shift by 1 so rolling windows use only *past* months (no leakage of current month)\n",
    "    shifted_avg = combined_co2_df[\"average\"].shift(1)\n",
    "    shifted_trend = combined_co2_df[\"trend\"].shift(1)\n",
    "    combined_co2_df[\"average_roll_3\"] = shifted_avg.rolling(window=3).mean()\n",
    "    combined_co2_df[\"average_roll_12\"] = shifted_avg.rolling(window=12).mean()\n",
    "    combined_co2_df[\"trend_roll_3\"] = shifted_trend.rolling(window=3).mean()\n",
    "    combined_co2_df[\"trend_roll_12\"] = shifted_trend.rolling(window=12).mean()\n",
    "    \n",
    "    # Extract only the new rows (with all features calculated)\n",
    "    co2_new_df = combined_co2_df[combined_co2_df['date'].isin(co2_new_df['date'])].copy()\n",
    "    \n",
    "    # Drop rows that don't have full history for all lags/rolls\n",
    "    co2_new_df = co2_new_df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Add time-based features for trend modeling\n",
    "    # Use year_min/year_max from historical data for consistent normalization\n",
    "    co2_new_df['year'] = pd.to_datetime(co2_new_df['date']).dt.year\n",
    "    co2_new_df['month'] = pd.to_datetime(co2_new_df['date']).dt.month\n",
    "    # Create cyclical month features (sin/cos for seasonal patterns)\n",
    "    co2_new_df['month_sin'] = np.sin(2 * np.pi * co2_new_df['month'] / 12)\n",
    "    co2_new_df['month_cos'] = np.cos(2 * np.pi * co2_new_df['month'] / 12)\n",
    "    # Normalize year using the same range as historical data (from backfill)\n",
    "    # Get year range from historical data to ensure consistent normalization\n",
    "    year_min = historical_co2_df['year'].min() if 'year' in historical_co2_df.columns else co2_new_df['year'].min()\n",
    "    year_max = historical_co2_df['year'].max() if 'year' in historical_co2_df.columns else co2_new_df['year'].max()\n",
    "    # If historical data doesn't have year column, calculate from date\n",
    "    if 'year' not in historical_co2_df.columns:\n",
    "        historical_co2_df['year'] = pd.to_datetime(historical_co2_df['date']).dt.year\n",
    "        year_min = historical_co2_df['year'].min()\n",
    "        year_max = historical_co2_df['year'].max()\n",
    "    co2_new_df['year_normalized'] = (co2_new_df['year'] - year_min) / (year_max - year_min)\n",
    "    # Add polynomial year term to capture acceleration\n",
    "    co2_new_df['year_normalized_squared'] = co2_new_df['year_normalized'] ** 2\n",
    "    # Add interaction terms: year * seasonality\n",
    "    co2_new_df['year_month_sin'] = co2_new_df['year_normalized'] * co2_new_df['month_sin']\n",
    "    co2_new_df['year_month_cos'] = co2_new_df['year_normalized'] * co2_new_df['month_cos']\n",
    "    \n",
    "    print(f\"Prepared {len(co2_new_df)} new CO‚ÇÇ record(s) with features\")\n",
    "    co2_new_df.head()\n",
    "else:\n",
    "    print(\"No new CO‚ÇÇ data to process\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4f6b6",
   "metadata": {},
   "source": [
    "##  üå°Ô∏è Retrieve Latest Temperature Data from NASA GISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804d8ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.35s) \n",
      "Latest date in feature store: 2025-11-01\n",
      "No new temperature data to add\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch NASA GISTEMP global land‚Äìocean monthly temperature anomalies (GLB.Ts+dSST)\n",
    "GISTEMP_URL = \"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\n",
    "\n",
    "response = requests.get(GISTEMP_URL)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Read CSV, skipping the first descriptive line so the header row is used\n",
    "wide_df = pd.read_csv(io.StringIO(response.text), skiprows=1)\n",
    "# Strip any whitespace from column names\n",
    "wide_df.columns = [c.strip() for c in wide_df.columns]\n",
    "\n",
    "# Expected monthly columns in GISTEMP table\n",
    "month_cols = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "wide_df = wide_df[[\"Year\"] + month_cols]\n",
    "\n",
    "# Reshape to long format: one row per (year, month)\n",
    "long_df = wide_df.melt(id_vars=\"Year\", value_vars=month_cols,\n",
    "                       var_name=\"month\", value_name=\"temp_anomaly\")\n",
    "\n",
    "# Drop missing values (marked as *** in original file)\n",
    "long_df = long_df.replace(\"***\", pd.NA).dropna(subset=[\"temp_anomaly\"]).copy()\n",
    "\n",
    "# Map month names to month numbers\n",
    "month_map = {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6,\n",
    "             \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12}\n",
    "long_df[\"Year\"] = long_df[\"Year\"].astype(int)\n",
    "long_df[\"month_num\"] = long_df[\"month\"].map(month_map)\n",
    "\n",
    "# Build a proper datetime (first day of each month)\n",
    "long_df[\"date\"] = pd.to_datetime({\n",
    "    \"year\": long_df[\"Year\"],\n",
    "    \"month\": long_df[\"month_num\"],\n",
    "    \"day\": 1,\n",
    "})\n",
    "\n",
    "# Convert anomaly to float (values are in ¬∞C anomalies)\n",
    "long_df[\"temp_anomaly\"] = long_df[\"temp_anomaly\"].astype(\"float32\")\n",
    "\n",
    "# Final tidy DataFrame\n",
    "temp_df = long_df[[\"date\", \"temp_anomaly\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Get the latest date from the feature store to find new data\n",
    "historical_temp_df = temp_fg.read()\n",
    "if len(historical_temp_df) > 0:\n",
    "    historical_temp_df['date'] = pd.to_datetime(historical_temp_df['date'])\n",
    "    # Remove timezone info if present (normalize to timezone-naive)\n",
    "    if historical_temp_df['date'].dt.tz is not None:\n",
    "        historical_temp_df['date'] = pd.to_datetime(historical_temp_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    latest_date = historical_temp_df['date'].max()\n",
    "    print(f\"Latest date in feature store: {latest_date.date()}\")\n",
    "    \n",
    "    # Filter to only new data (after latest date)\n",
    "    temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
    "    # Ensure timezone-naive for comparison\n",
    "    if temp_df['date'].dt.tz is not None:\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    temp_new_df = temp_df[temp_df['date'] > latest_date].copy()\n",
    "    \n",
    "    if len(temp_new_df) == 0:\n",
    "        print(\"No new temperature data to add\")\n",
    "        temp_new_df = pd.DataFrame()  # Empty DataFrame\n",
    "    else:\n",
    "        print(f\"Found {len(temp_new_df)} new month(s) of temperature data\")\n",
    "else:\n",
    "    print(\"No historical data found in feature store - this should not happen if backfill ran first\")\n",
    "    temp_new_df = pd.DataFrame()  # Empty DataFrame\n",
    "\n",
    "temp_new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67215e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new temperature data to process\n"
     ]
    }
   ],
   "source": [
    "if len(temp_new_df) > 0:\n",
    "    # Get historical data to calculate lags and rolling means\n",
    "    # We need enough history for the maximum lag (12 months)\n",
    "    historical_temp_df = temp_fg.read()\n",
    "    historical_temp_df['date'] = pd.to_datetime(historical_temp_df['date'])\n",
    "    # Remove timezone info if present (normalize to timezone-naive)\n",
    "    if historical_temp_df['date'].dt.tz is not None:\n",
    "        historical_temp_df['date'] = pd.to_datetime(historical_temp_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    historical_temp_df = historical_temp_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Ensure new data dates are also timezone-naive\n",
    "    temp_new_df['date'] = pd.to_datetime(temp_new_df['date'])\n",
    "    if temp_new_df['date'].dt.tz is not None:\n",
    "        temp_new_df['date'] = pd.to_datetime(temp_new_df['date'].dt.tz_convert('UTC'), utc=False)\n",
    "    \n",
    "    # Combine historical and new data for feature engineering\n",
    "    combined_temp_df = pd.concat([historical_temp_df[['date', 'temp_anomaly']], \n",
    "                                   temp_new_df[['date', 'temp_anomaly']]], \n",
    "                                  ignore_index=True)\n",
    "    combined_temp_df = combined_temp_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Add lag features for the main target series (temperature anomaly)\n",
    "    for k in [1, 2, 3, 6, 12]:\n",
    "        combined_temp_df[f\"temp_anomaly_lag_{k}\"] = combined_temp_df[\"temp_anomaly\"].shift(k)\n",
    "    \n",
    "    # Add rolling means over the temperature anomaly series\n",
    "    # IMPORTANT: shift by 1 so the rolling window uses only *past* months (no leakage of current month)\n",
    "    shifted_temp = combined_temp_df[\"temp_anomaly\"].shift(1)\n",
    "    combined_temp_df[\"temp_anomaly_roll_3\"] = shifted_temp.rolling(window=3).mean()\n",
    "    combined_temp_df[\"temp_anomaly_roll_12\"] = shifted_temp.rolling(window=12).mean()\n",
    "    \n",
    "    # Add time-based features for temperature trend modeling (consistent with backfill)\n",
    "    combined_temp_df['year'] = pd.to_datetime(combined_temp_df['date']).dt.year\n",
    "    combined_temp_df['month'] = pd.to_datetime(combined_temp_df['date']).dt.month\n",
    "    combined_temp_df['month_sin'] = np.sin(2 * np.pi * combined_temp_df['month'] / 12)\n",
    "    combined_temp_df['month_cos'] = np.cos(2 * np.pi * combined_temp_df['month'] / 12)\n",
    "    \n",
    "    # Normalize year using the same range as historical data to keep trend consistent\n",
    "    if 'year' in historical_temp_df.columns:\n",
    "        year_min_temp = historical_temp_df['year'].min()\n",
    "        year_max_temp = historical_temp_df['year'].max()\n",
    "    else:\n",
    "        historical_temp_df['year'] = pd.to_datetime(historical_temp_df['date']).dt.year\n",
    "        year_min_temp = historical_temp_df['year'].min()\n",
    "        year_max_temp = historical_temp_df['year'].max()\n",
    "    combined_temp_df['year_normalized'] = (combined_temp_df['year'] - year_min_temp) / (year_max_temp - year_min_temp)\n",
    "    combined_temp_df['year_normalized_squared'] = combined_temp_df['year_normalized'] ** 2\n",
    "    combined_temp_df['year_month_sin'] = combined_temp_df['year_normalized'] * combined_temp_df['month_sin']\n",
    "    combined_temp_df['year_month_cos'] = combined_temp_df['year_normalized'] * combined_temp_df['month_cos']\n",
    "    \n",
    "    # Extract only the new rows (with all features calculated)\n",
    "    temp_new_df = combined_temp_df[combined_temp_df['date'].isin(temp_new_df['date'])].copy()\n",
    "    \n",
    "    # Drop rows that don't have full history for all lags/rolls\n",
    "    temp_new_df = temp_new_df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Prepared {len(temp_new_df)} new temperature record(s) with features\")\n",
    "    temp_new_df.head()\n",
    "else:\n",
    "    print(\"No new temperature data to process\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc9cf5",
   "metadata": {},
   "source": [
    "## Uploading new data to the Feature Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1088693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new CO‚ÇÇ data to insert\n"
     ]
    }
   ],
   "source": [
    "# Insert new CO‚ÇÇ data if available\n",
    "if len(co2_new_df) > 0:\n",
    "    # Skip validation report saving to avoid Hopsworks server errors (500 error when saving report)\n",
    "    co2_fg.insert(co2_new_df, validation_options={\"save_report\": False})\n",
    "    print(f\"Inserted {len(co2_new_df)} new CO‚ÇÇ record(s)\")\n",
    "else:\n",
    "    print(\"No new CO‚ÇÇ data to insert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3daa0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new temperature data to insert\n"
     ]
    }
   ],
   "source": [
    "# Insert new temperature data if available\n",
    "if len(temp_new_df) > 0:\n",
    "    # Skip validation report saving to avoid Hopsworks server errors (500 error when saving report)\n",
    "    temp_fg.insert(temp_new_df, wait=True, validation_options={\"save_report\": False})\n",
    "    print(f\"Inserted {len(temp_new_df)} new temperature record(s)\")\n",
    "else:\n",
    "    print(\"No new temperature data to insert\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
